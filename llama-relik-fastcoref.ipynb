{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevereiner/llama-relik/blob/main/llama-relik-fastcoref.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Neo4j graph database info\n",
        "# Recommended: using Neo4j Aura, which provides a free cloud instance that can easily be accessed from a Google Colab notebook\n",
        "username=\"neo4j\"\n",
        "password=\"your password\"\n",
        "url=\"neo4j+s://xxxxxxxx.databases.neo4j.io\"\n",
        "\n",
        "import os\n",
        "# Your OpenAI key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-your-key\""
      ],
      "metadata": {
        "id": "ZlKj1hrgwUtl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm-clFDftFpb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install --quiet fastcoref spacy\n",
        "!pip install --quiet llama-index-extractors-relik llama-index-graph-stores-neo4j llama-index-llms-openai llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "ap8N4PPmtHj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "s4Je9ehtnUFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.graph_stores.neo4j import Neo4jPGStore\n",
        "\n",
        "graph_store = Neo4jPGStore(\n",
        "    username=username,\n",
        "    password=password,\n",
        "    url=url,\n",
        "    refresh_schema=False\n",
        ")"
      ],
      "metadata": {
        "id": "yN_e-JQpty56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "NUMBER_OF_ARTICLES = 10\n",
        "news = pd.read_csv(\"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\")\n",
        "news = news.head(NUMBER_OF_ARTICLES)"
      ],
      "metadata": {
        "id": "OR2i0hAiH1Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastcoref import spacy_component\n",
        "import spacy\n",
        "coref_nlp = spacy.load('en_core_web_lg')\n",
        "coref_nlp.add_pipe('fastcoref')\n",
        "\n",
        "text = 'Alice goes down the rabbit hole. Where she would discover a new reality beyond her expectations.'\n",
        "doc = coref_nlp(text, component_cfg={\"fastcoref\": {'resolve_text': True}})\n",
        "doc._.coref_clusters\n",
        "print(doc._.resolved_text)\n",
        "\n",
        "\n",
        "def coref_text(text):\n",
        "    coref_doc = coref_nlp(text, component_cfg={\"fastcoref\": {'resolve_text': True}})\n",
        "    resolved_text = coref_doc._.resolved_text\n",
        "    return resolved_text\n",
        "\n",
        "print(\n",
        "    coref_text(\"Tomaz is so cool. He can solve various Python dependencies and not cry\")\n",
        ")"
      ],
      "metadata": {
        "id": "xBIR3kSttYdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "from datetime import datetime\n",
        "\n",
        "news[\"coref_text\"] = news[\"text\"].apply(coref_text)\n",
        "documents = [\n",
        "    Document(text=f\"{row['title']}: {row['coref_text']}\") for i, row in news.iterrows()\n",
        "]\n",
        "\n",
        "\n",
        "print(coref_text(news['text'][5]))"
      ],
      "metadata": {
        "id": "5no1dHu_tRKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.extractors.relik.base import RelikPathExtractor\n",
        "\n",
        "relik = RelikPathExtractor(\n",
        "    model=\"relik-ie/relik-relation-extraction-small\", model_config={\"skip_metadata\": True}\n",
        ")\n",
        "\n",
        "# Use on Pro Collab with GPU\n",
        "# relik = RelikPathExtractor(\n",
        "#    model=\"relik-ie/relik-cie-small\", model_config={\"skip_metadata\": True, \"device\":\"cuda\"}\n",
        "# )"
      ],
      "metadata": {
        "id": "rdqApJWxWipF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o\", temperature=0.0)\n",
        "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "6d6bG3UzXOat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PropertyGraphIndex\n",
        "\n",
        "index = PropertyGraphIndex.from_documents(\n",
        "    documents,\n",
        "    kg_extractors=[relik],\n",
        "    llm=llm,\n",
        "    embed_model=embed_model,\n",
        "    property_graph_store=graph_store,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "metadata": {
        "id": "EUpUmP8WlzmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(include_text=True)\n",
        "\n",
        "response = query_engine.query(\"What happened at Ryanair?\")\n",
        "\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "h0hwgUc8mHu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHiv4JUjGBmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}